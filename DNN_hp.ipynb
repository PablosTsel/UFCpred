{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN with Hyper-Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1336\n",
      "0    1336\n",
      "Name: Winner, dtype: int64\n",
      "X_train shape: (2137, 42) | X_test shape: (535, 42) | y_train shape: (2137,) | y_test shape: (535,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # disable GPU\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "\n",
    "#hyper-parameter tuning imports\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import time\n",
    "LOG_DIR = f\"{int(time.time())}\" # folder names as a timestamp\n",
    "\n",
    "SEED = 111 # constant seed for reproducibility\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "df = pd.read_csv(\"UFC_TRAIN.csv\")\n",
    "\n",
    "# tackling imbalance issue\n",
    "theMin = df[\"Winner\"].value_counts().min()\n",
    "minority = df[df[\"Winner\"]==1].iloc[0:theMin]\n",
    "undersampleMaj = df[df[\"Winner\"]==0].iloc[0:theMin]\n",
    "df = pd.concat([minority, undersampleMaj], axis=0)\n",
    "print(df[\"Winner\"].value_counts())\n",
    "\n",
    "# train/test split\n",
    "X = df.drop([\"Winner\",\"B_fighter\",\"R_fighter\"], axis=1).values\n",
    "y = df[\"Winner\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape} | X_test shape: {X_test.shape} | y_train shape: {y_train.shape} | y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Parameters\n",
    "MIN = 30\n",
    "MAX = 256\n",
    "STEP = 16\n",
    "MAX_TRIALS = 2\n",
    "EXE_PER_TRIAL = 1\n",
    "EPOCHS = 10\n",
    "PATIENCE = 16\n",
    "\n",
    "# function to build the model (argument: hyper-parameter)\n",
    "def build_model(hp):\n",
    "    # model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # first layer's no. of neurons = hp.Int range of values to test\n",
    "    model.add(Dense(hp.Int(\"input_units\", min_value=MIN, max_value=MAX, step=STEP), activation='relu'))\n",
    "    \n",
    "    # range of 1 to 10 layers to test\n",
    "    for i in range(hp.Int(\"no. Of Hidden Layers\", 1, 5)):\n",
    "        # for each added layer, again test range of neurons and add dropout\n",
    "        model.add(Dense(hp.Int(f\"Hidden_layer_{i+1}_units\", min_value=MIN, max_value=MAX, step=STEP), activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "        build_model, # name of the function that builds the model\n",
    "        objective=\"val_accuracy\", # the thing that we're interested to trace\n",
    "        max_trials = MAX_TRIALS, # no. of combinations to try\n",
    "        executions_per_trial = EXE_PER_TRIAL, # no. of times to train each combination (true avg)\n",
    "        directory=LOG_DIR) # directory to save the outputs\n",
    "\n",
    "# prevent divergence of loss & val_loss via early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2137 samples, validate on 535 samples\n",
      "Epoch 1/10\n",
      "2137/2137 [==============================] - ETA: 2:52 - loss: 0.6922 - accuracy: 0.53 - ETA: 33s - loss: 0.6956 - accuracy: 0.5063 - ETA: 15s - loss: 0.6974 - accuracy: 0.506 - ETA: 11s - loss: 0.6990 - accuracy: 0.495 - ETA: 8s - loss: 0.6962 - accuracy: 0.500 - ETA: 6s - loss: 0.6956 - accuracy: 0.50 - ETA: 4s - loss: 0.6960 - accuracy: 0.49 - ETA: 3s - loss: 0.6965 - accuracy: 0.48 - ETA: 3s - loss: 0.6957 - accuracy: 0.49 - ETA: 2s - loss: 0.6959 - accuracy: 0.50 - ETA: 1s - loss: 0.6957 - accuracy: 0.50 - ETA: 1s - loss: 0.6958 - accuracy: 0.50 - ETA: 1s - loss: 0.6954 - accuracy: 0.50 - ETA: 0s - loss: 0.6953 - accuracy: 0.49 - ETA: 0s - loss: 0.6954 - accuracy: 0.50 - ETA: 0s - loss: 0.6952 - accuracy: 0.49 - 4s 2ms/sample - loss: 0.6953 - accuracy: 0.4988 - val_loss: 0.6930 - val_accuracy: 0.5084\n",
      "Epoch 2/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.7122 - accuracy: 0.40 - ETA: 1s - loss: 0.7096 - accuracy: 0.48 - ETA: 0s - loss: 0.7027 - accuracy: 0.52 - ETA: 0s - loss: 0.7028 - accuracy: 0.51 - ETA: 0s - loss: 0.7026 - accuracy: 0.49 - ETA: 0s - loss: 0.7014 - accuracy: 0.48 - ETA: 0s - loss: 0.6995 - accuracy: 0.49 - ETA: 0s - loss: 0.6978 - accuracy: 0.49 - ETA: 0s - loss: 0.6980 - accuracy: 0.48 - ETA: 0s - loss: 0.6964 - accuracy: 0.50 - ETA: 0s - loss: 0.6961 - accuracy: 0.50 - ETA: 0s - loss: 0.6958 - accuracy: 0.49 - ETA: 0s - loss: 0.6951 - accuracy: 0.50 - ETA: 0s - loss: 0.6947 - accuracy: 0.50 - ETA: 0s - loss: 0.6948 - accuracy: 0.49 - ETA: 0s - loss: 0.6951 - accuracy: 0.49 - ETA: 0s - loss: 0.6950 - accuracy: 0.49 - 1s 506us/sample - loss: 0.6951 - accuracy: 0.4932 - val_loss: 0.6931 - val_accuracy: 0.5084\n",
      "Epoch 3/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6868 - accuracy: 0.53 - ETA: 0s - loss: 0.6937 - accuracy: 0.48 - ETA: 0s - loss: 0.6932 - accuracy: 0.53 - ETA: 0s - loss: 0.6943 - accuracy: 0.52 - ETA: 0s - loss: 0.6935 - accuracy: 0.51 - ETA: 0s - loss: 0.6946 - accuracy: 0.51 - ETA: 0s - loss: 0.6944 - accuracy: 0.50 - ETA: 0s - loss: 0.6947 - accuracy: 0.49 - ETA: 0s - loss: 0.6939 - accuracy: 0.49 - ETA: 0s - loss: 0.6941 - accuracy: 0.49 - ETA: 0s - loss: 0.6931 - accuracy: 0.51 - ETA: 0s - loss: 0.6935 - accuracy: 0.50 - ETA: 0s - loss: 0.6938 - accuracy: 0.49 - ETA: 0s - loss: 0.6938 - accuracy: 0.49 - ETA: 0s - loss: 0.6942 - accuracy: 0.49 - ETA: 0s - loss: 0.6942 - accuracy: 0.49 - 1s 492us/sample - loss: 0.6941 - accuracy: 0.4932 - val_loss: 0.6931 - val_accuracy: 0.5084\n",
      "Epoch 4/10\n",
      "2137/2137 [==============================] - ETA: 0s - loss: 0.6998 - accuracy: 0.53 - ETA: 0s - loss: 0.6943 - accuracy: 0.52 - ETA: 0s - loss: 0.6929 - accuracy: 0.53 - ETA: 0s - loss: 0.6927 - accuracy: 0.53 - ETA: 0s - loss: 0.6918 - accuracy: 0.54 - ETA: 0s - loss: 0.6930 - accuracy: 0.53 - ETA: 0s - loss: 0.6941 - accuracy: 0.52 - ETA: 0s - loss: 0.6937 - accuracy: 0.51 - ETA: 0s - loss: 0.6937 - accuracy: 0.50 - ETA: 0s - loss: 0.6937 - accuracy: 0.50 - ETA: 0s - loss: 0.6934 - accuracy: 0.50 - ETA: 0s - loss: 0.6934 - accuracy: 0.50 - ETA: 0s - loss: 0.6934 - accuracy: 0.50 - ETA: 0s - loss: 0.6931 - accuracy: 0.50 - 1s 448us/sample - loss: 0.6931 - accuracy: 0.5077 - val_loss: 0.6931 - val_accuracy: 0.5738\n",
      "Epoch 5/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6908 - accuracy: 0.46 - ETA: 1s - loss: 0.6963 - accuracy: 0.50 - ETA: 0s - loss: 0.6945 - accuracy: 0.51 - ETA: 1s - loss: 0.6944 - accuracy: 0.50 - ETA: 1s - loss: 0.6944 - accuracy: 0.50 - ETA: 1s - loss: 0.6931 - accuracy: 0.52 - ETA: 1s - loss: 0.6939 - accuracy: 0.52 - ETA: 0s - loss: 0.6940 - accuracy: 0.51 - ETA: 0s - loss: 0.6936 - accuracy: 0.51 - ETA: 0s - loss: 0.6937 - accuracy: 0.49 - ETA: 0s - loss: 0.6940 - accuracy: 0.48 - ETA: 0s - loss: 0.6945 - accuracy: 0.48 - ETA: 0s - loss: 0.6947 - accuracy: 0.48 - ETA: 0s - loss: 0.6948 - accuracy: 0.47 - ETA: 0s - loss: 0.6947 - accuracy: 0.47 - ETA: 0s - loss: 0.6949 - accuracy: 0.47 - ETA: 0s - loss: 0.6949 - accuracy: 0.47 - ETA: 0s - loss: 0.6948 - accuracy: 0.48 - ETA: 0s - loss: 0.6945 - accuracy: 0.48 - 1s 599us/sample - loss: 0.6944 - accuracy: 0.4843 - val_loss: 0.6931 - val_accuracy: 0.5084\n",
      "Epoch 6/10\n",
      "2137/2137 [==============================] - ETA: 0s - loss: 0.6911 - accuracy: 0.53 - ETA: 0s - loss: 0.6927 - accuracy: 0.52 - ETA: 0s - loss: 0.6919 - accuracy: 0.50 - ETA: 0s - loss: 0.6917 - accuracy: 0.51 - ETA: 0s - loss: 0.6919 - accuracy: 0.51 - ETA: 0s - loss: 0.6924 - accuracy: 0.50 - ETA: 0s - loss: 0.6929 - accuracy: 0.49 - ETA: 0s - loss: 0.6930 - accuracy: 0.49 - ETA: 0s - loss: 0.6928 - accuracy: 0.49 - ETA: 0s - loss: 0.6923 - accuracy: 0.50 - ETA: 0s - loss: 0.6924 - accuracy: 0.50 - ETA: 0s - loss: 0.6927 - accuracy: 0.50 - ETA: 0s - loss: 0.6929 - accuracy: 0.50 - ETA: 0s - loss: 0.6930 - accuracy: 0.50 - 1s 454us/sample - loss: 0.6930 - accuracy: 0.5002 - val_loss: 0.6931 - val_accuracy: 0.5215\n",
      "Epoch 7/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6995 - accuracy: 0.43 - ETA: 0s - loss: 0.6946 - accuracy: 0.53 - ETA: 0s - loss: 0.6962 - accuracy: 0.49 - ETA: 0s - loss: 0.6948 - accuracy: 0.50 - ETA: 0s - loss: 0.6946 - accuracy: 0.49 - ETA: 0s - loss: 0.6943 - accuracy: 0.49 - ETA: 0s - loss: 0.6935 - accuracy: 0.50 - ETA: 0s - loss: 0.6934 - accuracy: 0.50 - ETA: 0s - loss: 0.6938 - accuracy: 0.50 - ETA: 0s - loss: 0.6936 - accuracy: 0.50 - ETA: 0s - loss: 0.6933 - accuracy: 0.50 - ETA: 0s - loss: 0.6933 - accuracy: 0.51 - ETA: 0s - loss: 0.6933 - accuracy: 0.51 - ETA: 0s - loss: 0.6936 - accuracy: 0.50 - ETA: 0s - loss: 0.6935 - accuracy: 0.50 - ETA: 0s - loss: 0.6933 - accuracy: 0.50 - ETA: 0s - loss: 0.6933 - accuracy: 0.50 - 1s 503us/sample - loss: 0.6934 - accuracy: 0.5030 - val_loss: 0.6930 - val_accuracy: 0.5084\n",
      "Epoch 8/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.7014 - accuracy: 0.43 - ETA: 0s - loss: 0.6927 - accuracy: 0.55 - ETA: 0s - loss: 0.6953 - accuracy: 0.48 - ETA: 0s - loss: 0.6940 - accuracy: 0.48 - ETA: 0s - loss: 0.6937 - accuracy: 0.49 - ETA: 0s - loss: 0.6938 - accuracy: 0.49 - ETA: 0s - loss: 0.6940 - accuracy: 0.49 - ETA: 0s - loss: 0.6936 - accuracy: 0.49 - ETA: 0s - loss: 0.6939 - accuracy: 0.48 - ETA: 0s - loss: 0.6936 - accuracy: 0.49 - ETA: 0s - loss: 0.6932 - accuracy: 0.49 - ETA: 0s - loss: 0.6933 - accuracy: 0.49 - ETA: 0s - loss: 0.6931 - accuracy: 0.50 - ETA: 0s - loss: 0.6936 - accuracy: 0.49 - ETA: 0s - loss: 0.6935 - accuracy: 0.49 - ETA: 0s - loss: 0.6936 - accuracy: 0.49 - ETA: 0s - loss: 0.6934 - accuracy: 0.49 - ETA: 0s - loss: 0.6934 - accuracy: 0.49 - ETA: 0s - loss: 0.6936 - accuracy: 0.48 - ETA: 0s - loss: 0.6936 - accuracy: 0.48 - ETA: 0s - loss: 0.6937 - accuracy: 0.48 - ETA: 0s - loss: 0.6935 - accuracy: 0.48 - ETA: 0s - loss: 0.6934 - accuracy: 0.48 - 1s 678us/sample - loss: 0.6935 - accuracy: 0.4848 - val_loss: 0.6931 - val_accuracy: 0.5084\n",
      "Epoch 9/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6866 - accuracy: 0.59 - ETA: 0s - loss: 0.6976 - accuracy: 0.50 - ETA: 0s - loss: 0.6957 - accuracy: 0.49 - ETA: 0s - loss: 0.6940 - accuracy: 0.49 - ETA: 0s - loss: 0.6936 - accuracy: 0.49 - ETA: 0s - loss: 0.6928 - accuracy: 0.50 - ETA: 0s - loss: 0.6939 - accuracy: 0.50 - ETA: 0s - loss: 0.6937 - accuracy: 0.50 - ETA: 0s - loss: 0.6941 - accuracy: 0.49 - ETA: 0s - loss: 0.6936 - accuracy: 0.49 - ETA: 0s - loss: 0.6935 - accuracy: 0.50 - ETA: 0s - loss: 0.6936 - accuracy: 0.49 - ETA: 0s - loss: 0.6938 - accuracy: 0.49 - ETA: 0s - loss: 0.6939 - accuracy: 0.49 - ETA: 0s - loss: 0.6938 - accuracy: 0.49 - ETA: 0s - loss: 0.6939 - accuracy: 0.49 - ETA: 0s - loss: 0.6939 - accuracy: 0.49 - 1s 512us/sample - loss: 0.6940 - accuracy: 0.4909 - val_loss: 0.6931 - val_accuracy: 0.5084\n",
      "Epoch 10/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6825 - accuracy: 0.71 - ETA: 0s - loss: 0.6924 - accuracy: 0.52 - ETA: 0s - loss: 0.6926 - accuracy: 0.52 - ETA: 0s - loss: 0.6926 - accuracy: 0.51 - ETA: 0s - loss: 0.6920 - accuracy: 0.51 - ETA: 0s - loss: 0.6922 - accuracy: 0.50 - ETA: 0s - loss: 0.6924 - accuracy: 0.50 - ETA: 0s - loss: 0.6931 - accuracy: 0.48 - ETA: 0s - loss: 0.6928 - accuracy: 0.49 - ETA: 0s - loss: 0.6928 - accuracy: 0.49 - ETA: 0s - loss: 0.6927 - accuracy: 0.49 - ETA: 0s - loss: 0.6929 - accuracy: 0.49 - ETA: 0s - loss: 0.6929 - accuracy: 0.50 - ETA: 0s - loss: 0.6932 - accuracy: 0.50 - ETA: 0s - loss: 0.6934 - accuracy: 0.50 - ETA: 0s - loss: 0.6931 - accuracy: 0.50 - ETA: 0s - loss: 0.6932 - accuracy: 0.50 - ETA: 0s - loss: 0.6932 - accuracy: 0.50 - 1s 518us/sample - loss: 0.6931 - accuracy: 0.5105 - val_loss: 0.6930 - val_accuracy: 0.5084\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Hidden_layer_1_units: 222</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-Hidden_layer_2_units: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Hidden_layer_3_units: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-Hidden_layer_4_units: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Hidden_layer_5_units: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-Hidden_layer_6_units: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Hidden_layer_7_units: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-Hidden_layer_8_units: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_units: 78</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-no. Of Hidden Layers: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.5738317966461182</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2137 samples, validate on 535 samples\n",
      "Epoch 1/10\n",
      "2137/2137 [==============================] - ETA: 3:48 - loss: 0.7423 - accuracy: 0.31 - ETA: 55s - loss: 0.7047 - accuracy: 0.4609 - ETA: 30s - loss: 0.7017 - accuracy: 0.473 - ETA: 20s - loss: 0.6969 - accuracy: 0.484 - ETA: 15s - loss: 0.6938 - accuracy: 0.500 - ETA: 13s - loss: 0.6927 - accuracy: 0.504 - ETA: 10s - loss: 0.6941 - accuracy: 0.503 - ETA: 9s - loss: 0.6953 - accuracy: 0.501 - ETA: 8s - loss: 0.6966 - accuracy: 0.49 - ETA: 7s - loss: 0.6981 - accuracy: 0.49 - ETA: 6s - loss: 0.6979 - accuracy: 0.49 - ETA: 5s - loss: 0.7001 - accuracy: 0.48 - ETA: 4s - loss: 0.7001 - accuracy: 0.49 - ETA: 4s - loss: 0.7023 - accuracy: 0.48 - ETA: 3s - loss: 0.7030 - accuracy: 0.48 - ETA: 3s - loss: 0.7029 - accuracy: 0.48 - ETA: 2s - loss: 0.7018 - accuracy: 0.48 - ETA: 2s - loss: 0.7018 - accuracy: 0.48 - ETA: 2s - loss: 0.7004 - accuracy: 0.48 - ETA: 1s - loss: 0.7000 - accuracy: 0.48 - ETA: 1s - loss: 0.6997 - accuracy: 0.48 - ETA: 1s - loss: 0.6997 - accuracy: 0.48 - ETA: 0s - loss: 0.6995 - accuracy: 0.48 - ETA: 0s - loss: 0.6999 - accuracy: 0.47 - ETA: 0s - loss: 0.7000 - accuracy: 0.47 - ETA: 0s - loss: 0.7000 - accuracy: 0.47 - 6s 3ms/sample - loss: 0.6999 - accuracy: 0.4736 - val_loss: 0.6934 - val_accuracy: 0.4916\n",
      "Epoch 2/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6983 - accuracy: 0.40 - ETA: 1s - loss: 0.6978 - accuracy: 0.41 - ETA: 1s - loss: 0.6955 - accuracy: 0.47 - ETA: 1s - loss: 0.6956 - accuracy: 0.48 - ETA: 1s - loss: 0.6954 - accuracy: 0.48 - ETA: 1s - loss: 0.6958 - accuracy: 0.47 - ETA: 1s - loss: 0.6959 - accuracy: 0.46 - ETA: 1s - loss: 0.6956 - accuracy: 0.47 - ETA: 1s - loss: 0.6945 - accuracy: 0.47 - ETA: 1s - loss: 0.6947 - accuracy: 0.47 - ETA: 1s - loss: 0.6942 - accuracy: 0.48 - ETA: 1s - loss: 0.6941 - accuracy: 0.48 - ETA: 1s - loss: 0.6940 - accuracy: 0.48 - ETA: 1s - loss: 0.6939 - accuracy: 0.48 - ETA: 1s - loss: 0.6940 - accuracy: 0.48 - ETA: 1s - loss: 0.6945 - accuracy: 0.47 - ETA: 0s - loss: 0.6946 - accuracy: 0.47 - ETA: 0s - loss: 0.6948 - accuracy: 0.47 - ETA: 0s - loss: 0.6948 - accuracy: 0.47 - ETA: 0s - loss: 0.6947 - accuracy: 0.47 - ETA: 0s - loss: 0.6947 - accuracy: 0.47 - ETA: 0s - loss: 0.6946 - accuracy: 0.47 - ETA: 0s - loss: 0.6949 - accuracy: 0.47 - ETA: 0s - loss: 0.6949 - accuracy: 0.47 - ETA: 0s - loss: 0.6951 - accuracy: 0.47 - ETA: 0s - loss: 0.6952 - accuracy: 0.47 - ETA: 0s - loss: 0.6951 - accuracy: 0.47 - ETA: 0s - loss: 0.6951 - accuracy: 0.47 - ETA: 0s - loss: 0.6950 - accuracy: 0.47 - ETA: 0s - loss: 0.6949 - accuracy: 0.47 - ETA: 0s - loss: 0.6949 - accuracy: 0.47 - ETA: 0s - loss: 0.6948 - accuracy: 0.47 - ETA: 0s - loss: 0.6949 - accuracy: 0.47 - ETA: 0s - loss: 0.6950 - accuracy: 0.47 - ETA: 0s - loss: 0.6948 - accuracy: 0.47 - ETA: 0s - loss: 0.6948 - accuracy: 0.48 - ETA: 0s - loss: 0.6950 - accuracy: 0.48 - ETA: 0s - loss: 0.6952 - accuracy: 0.48 - ETA: 0s - loss: 0.6951 - accuracy: 0.48 - ETA: 0s - loss: 0.6951 - accuracy: 0.48 - 3s 1ms/sample - loss: 0.6952 - accuracy: 0.4801 - val_loss: 0.6933 - val_accuracy: 0.4916\n",
      "Epoch 3/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6919 - accuracy: 0.40 - ETA: 1s - loss: 0.6942 - accuracy: 0.53 - ETA: 1s - loss: 0.6936 - accuracy: 0.48 - ETA: 1s - loss: 0.6950 - accuracy: 0.50 - ETA: 1s - loss: 0.6929 - accuracy: 0.50 - ETA: 1s - loss: 0.6940 - accuracy: 0.49 - ETA: 1s - loss: 0.6941 - accuracy: 0.49 - ETA: 1s - loss: 0.6940 - accuracy: 0.48 - ETA: 1s - loss: 0.6940 - accuracy: 0.49 - ETA: 1s - loss: 0.6940 - accuracy: 0.49 - ETA: 1s - loss: 0.6937 - accuracy: 0.49 - ETA: 1s - loss: 0.6947 - accuracy: 0.48 - ETA: 1s - loss: 0.6947 - accuracy: 0.48 - ETA: 0s - loss: 0.6946 - accuracy: 0.48 - ETA: 0s - loss: 0.6944 - accuracy: 0.49 - ETA: 0s - loss: 0.6938 - accuracy: 0.49 - ETA: 0s - loss: 0.6938 - accuracy: 0.50 - ETA: 0s - loss: 0.6936 - accuracy: 0.50 - ETA: 0s - loss: 0.6935 - accuracy: 0.50 - ETA: 0s - loss: 0.6935 - accuracy: 0.50 - ETA: 0s - loss: 0.6933 - accuracy: 0.51 - ETA: 0s - loss: 0.6931 - accuracy: 0.51 - ETA: 0s - loss: 0.6932 - accuracy: 0.50 - ETA: 0s - loss: 0.6932 - accuracy: 0.51 - ETA: 0s - loss: 0.6930 - accuracy: 0.51 - ETA: 0s - loss: 0.6932 - accuracy: 0.51 - ETA: 0s - loss: 0.6932 - accuracy: 0.51 - ETA: 0s - loss: 0.6931 - accuracy: 0.51 - ETA: 0s - loss: 0.6930 - accuracy: 0.51 - ETA: 0s - loss: 0.6929 - accuracy: 0.51 - 2s 927us/sample - loss: 0.6929 - accuracy: 0.5143 - val_loss: 0.6933 - val_accuracy: 0.4916\n",
      "Epoch 4/10\n",
      "2137/2137 [==============================] - ETA: 2s - loss: 0.6852 - accuracy: 0.59 - ETA: 2s - loss: 0.6913 - accuracy: 0.52 - ETA: 1s - loss: 0.6934 - accuracy: 0.50 - ETA: 1s - loss: 0.6936 - accuracy: 0.50 - ETA: 1s - loss: 0.6928 - accuracy: 0.51 - ETA: 1s - loss: 0.6943 - accuracy: 0.51 - ETA: 1s - loss: 0.6936 - accuracy: 0.51 - ETA: 1s - loss: 0.6946 - accuracy: 0.49 - ETA: 1s - loss: 0.6951 - accuracy: 0.48 - ETA: 1s - loss: 0.6952 - accuracy: 0.47 - ETA: 1s - loss: 0.6946 - accuracy: 0.48 - ETA: 0s - loss: 0.6938 - accuracy: 0.49 - ETA: 0s - loss: 0.6941 - accuracy: 0.49 - ETA: 0s - loss: 0.6941 - accuracy: 0.49 - ETA: 0s - loss: 0.6943 - accuracy: 0.49 - ETA: 0s - loss: 0.6943 - accuracy: 0.49 - ETA: 0s - loss: 0.6943 - accuracy: 0.49 - ETA: 0s - loss: 0.6941 - accuracy: 0.49 - ETA: 0s - loss: 0.6941 - accuracy: 0.49 - ETA: 0s - loss: 0.6941 - accuracy: 0.49 - ETA: 0s - loss: 0.6942 - accuracy: 0.49 - ETA: 0s - loss: 0.6940 - accuracy: 0.49 - ETA: 0s - loss: 0.6940 - accuracy: 0.49 - ETA: 0s - loss: 0.6938 - accuracy: 0.49 - ETA: 0s - loss: 0.6938 - accuracy: 0.49 - ETA: 0s - loss: 0.6938 - accuracy: 0.49 - ETA: 0s - loss: 0.6936 - accuracy: 0.49 - ETA: 0s - loss: 0.6935 - accuracy: 0.49 - ETA: 0s - loss: 0.6932 - accuracy: 0.50 - ETA: 0s - loss: 0.6931 - accuracy: 0.50 - ETA: 0s - loss: 0.6931 - accuracy: 0.50 - ETA: 0s - loss: 0.6927 - accuracy: 0.50 - ETA: 0s - loss: 0.6927 - accuracy: 0.50 - ETA: 0s - loss: 0.6929 - accuracy: 0.50 - ETA: 0s - loss: 0.6928 - accuracy: 0.50 - ETA: 0s - loss: 0.6929 - accuracy: 0.50 - 2s 1ms/sample - loss: 0.6929 - accuracy: 0.5054 - val_loss: 0.6936 - val_accuracy: 0.4916\n",
      "Epoch 5/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6966 - accuracy: 0.46 - ETA: 1s - loss: 0.6898 - accuracy: 0.44 - ETA: 1s - loss: 0.6872 - accuracy: 0.51 - ETA: 1s - loss: 0.6902 - accuracy: 0.52 - ETA: 1s - loss: 0.6924 - accuracy: 0.50 - ETA: 1s - loss: 0.6938 - accuracy: 0.51 - ETA: 1s - loss: 0.6947 - accuracy: 0.50 - ETA: 1s - loss: 0.6963 - accuracy: 0.48 - ETA: 1s - loss: 0.6977 - accuracy: 0.47 - ETA: 1s - loss: 0.6977 - accuracy: 0.47 - ETA: 1s - loss: 0.6977 - accuracy: 0.47 - ETA: 1s - loss: 0.6965 - accuracy: 0.47 - ETA: 1s - loss: 0.6966 - accuracy: 0.47 - ETA: 0s - loss: 0.6964 - accuracy: 0.47 - ETA: 0s - loss: 0.6958 - accuracy: 0.48 - ETA: 0s - loss: 0.6965 - accuracy: 0.48 - ETA: 0s - loss: 0.6960 - accuracy: 0.48 - ETA: 0s - loss: 0.6953 - accuracy: 0.48 - ETA: 0s - loss: 0.6947 - accuracy: 0.49 - ETA: 0s - loss: 0.6949 - accuracy: 0.48 - ETA: 0s - loss: 0.6955 - accuracy: 0.48 - ETA: 0s - loss: 0.6958 - accuracy: 0.48 - ETA: 0s - loss: 0.6952 - accuracy: 0.49 - ETA: 0s - loss: 0.6952 - accuracy: 0.49 - ETA: 0s - loss: 0.6950 - accuracy: 0.49 - ETA: 0s - loss: 0.6952 - accuracy: 0.49 - ETA: 0s - loss: 0.6952 - accuracy: 0.49 - ETA: 0s - loss: 0.6949 - accuracy: 0.49 - 2s 876us/sample - loss: 0.6951 - accuracy: 0.4937 - val_loss: 0.6932 - val_accuracy: 0.4916\n",
      "Epoch 6/10\n",
      "2137/2137 [==============================] - ETA: 2s - loss: 0.7048 - accuracy: 0.40 - ETA: 2s - loss: 0.7003 - accuracy: 0.43 - ETA: 1s - loss: 0.7022 - accuracy: 0.46 - ETA: 1s - loss: 0.7008 - accuracy: 0.47 - ETA: 1s - loss: 0.7021 - accuracy: 0.46 - ETA: 1s - loss: 0.7002 - accuracy: 0.47 - ETA: 1s - loss: 0.6989 - accuracy: 0.48 - ETA: 1s - loss: 0.6985 - accuracy: 0.47 - ETA: 1s - loss: 0.6982 - accuracy: 0.48 - ETA: 1s - loss: 0.6979 - accuracy: 0.48 - ETA: 1s - loss: 0.6980 - accuracy: 0.48 - ETA: 1s - loss: 0.6976 - accuracy: 0.48 - ETA: 1s - loss: 0.6973 - accuracy: 0.47 - ETA: 0s - loss: 0.6969 - accuracy: 0.48 - ETA: 0s - loss: 0.6969 - accuracy: 0.48 - ETA: 0s - loss: 0.6965 - accuracy: 0.48 - ETA: 0s - loss: 0.6964 - accuracy: 0.48 - ETA: 0s - loss: 0.6966 - accuracy: 0.47 - ETA: 0s - loss: 0.6965 - accuracy: 0.47 - ETA: 0s - loss: 0.6967 - accuracy: 0.48 - ETA: 0s - loss: 0.6963 - accuracy: 0.48 - ETA: 0s - loss: 0.6961 - accuracy: 0.48 - ETA: 0s - loss: 0.6961 - accuracy: 0.48 - ETA: 0s - loss: 0.6959 - accuracy: 0.48 - ETA: 0s - loss: 0.6962 - accuracy: 0.48 - ETA: 0s - loss: 0.6962 - accuracy: 0.48 - ETA: 0s - loss: 0.6961 - accuracy: 0.48 - ETA: 0s - loss: 0.6961 - accuracy: 0.48 - 2s 886us/sample - loss: 0.6962 - accuracy: 0.4867 - val_loss: 0.6933 - val_accuracy: 0.4916\n",
      "Epoch 7/10\n",
      "2137/2137 [==============================] - ETA: 2s - loss: 0.6899 - accuracy: 0.71 - ETA: 2s - loss: 0.6926 - accuracy: 0.59 - ETA: 2s - loss: 0.6922 - accuracy: 0.57 - ETA: 2s - loss: 0.6909 - accuracy: 0.57 - ETA: 2s - loss: 0.6915 - accuracy: 0.55 - ETA: 2s - loss: 0.6919 - accuracy: 0.54 - ETA: 1s - loss: 0.6930 - accuracy: 0.53 - ETA: 1s - loss: 0.6934 - accuracy: 0.51 - ETA: 1s - loss: 0.6931 - accuracy: 0.51 - ETA: 1s - loss: 0.6933 - accuracy: 0.51 - ETA: 1s - loss: 0.6933 - accuracy: 0.50 - ETA: 1s - loss: 0.6933 - accuracy: 0.51 - ETA: 1s - loss: 0.6933 - accuracy: 0.50 - ETA: 1s - loss: 0.6931 - accuracy: 0.51 - ETA: 1s - loss: 0.6931 - accuracy: 0.51 - ETA: 1s - loss: 0.6933 - accuracy: 0.50 - ETA: 1s - loss: 0.6931 - accuracy: 0.50 - ETA: 1s - loss: 0.6931 - accuracy: 0.50 - ETA: 1s - loss: 0.6928 - accuracy: 0.50 - ETA: 1s - loss: 0.6928 - accuracy: 0.49 - ETA: 1s - loss: 0.6928 - accuracy: 0.50 - ETA: 1s - loss: 0.6928 - accuracy: 0.50 - ETA: 1s - loss: 0.6928 - accuracy: 0.50 - ETA: 0s - loss: 0.6929 - accuracy: 0.50 - ETA: 0s - loss: 0.6932 - accuracy: 0.50 - ETA: 0s - loss: 0.6933 - accuracy: 0.49 - ETA: 0s - loss: 0.6934 - accuracy: 0.49 - ETA: 0s - loss: 0.6936 - accuracy: 0.49 - ETA: 0s - loss: 0.6934 - accuracy: 0.49 - ETA: 0s - loss: 0.6933 - accuracy: 0.49 - ETA: 0s - loss: 0.6934 - accuracy: 0.49 - ETA: 0s - loss: 0.6934 - accuracy: 0.49 - ETA: 0s - loss: 0.6933 - accuracy: 0.49 - ETA: 0s - loss: 0.6933 - accuracy: 0.50 - ETA: 0s - loss: 0.6935 - accuracy: 0.50 - ETA: 0s - loss: 0.6936 - accuracy: 0.49 - 2s 1ms/sample - loss: 0.6936 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5028\n",
      "Epoch 8/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6955 - accuracy: 0.37 - ETA: 1s - loss: 0.6933 - accuracy: 0.44 - ETA: 1s - loss: 0.6946 - accuracy: 0.46 - ETA: 1s - loss: 0.6953 - accuracy: 0.46 - ETA: 1s - loss: 0.6948 - accuracy: 0.47 - ETA: 1s - loss: 0.6946 - accuracy: 0.47 - ETA: 1s - loss: 0.6945 - accuracy: 0.47 - ETA: 1s - loss: 0.6943 - accuracy: 0.47 - ETA: 1s - loss: 0.6940 - accuracy: 0.48 - ETA: 1s - loss: 0.6939 - accuracy: 0.49 - ETA: 1s - loss: 0.6942 - accuracy: 0.48 - ETA: 1s - loss: 0.6942 - accuracy: 0.49 - ETA: 1s - loss: 0.6944 - accuracy: 0.49 - ETA: 1s - loss: 0.6944 - accuracy: 0.48 - ETA: 1s - loss: 0.6945 - accuracy: 0.49 - ETA: 1s - loss: 0.6942 - accuracy: 0.49 - ETA: 1s - loss: 0.6940 - accuracy: 0.50 - ETA: 1s - loss: 0.6941 - accuracy: 0.49 - ETA: 1s - loss: 0.6941 - accuracy: 0.49 - ETA: 1s - loss: 0.6944 - accuracy: 0.48 - ETA: 1s - loss: 0.6944 - accuracy: 0.49 - ETA: 0s - loss: 0.6944 - accuracy: 0.49 - ETA: 0s - loss: 0.6943 - accuracy: 0.49 - ETA: 0s - loss: 0.6943 - accuracy: 0.49 - ETA: 0s - loss: 0.6943 - accuracy: 0.49 - ETA: 0s - loss: 0.6943 - accuracy: 0.49 - ETA: 0s - loss: 0.6944 - accuracy: 0.49 - ETA: 0s - loss: 0.6944 - accuracy: 0.49 - ETA: 0s - loss: 0.6944 - accuracy: 0.49 - ETA: 0s - loss: 0.6945 - accuracy: 0.48 - ETA: 0s - loss: 0.6944 - accuracy: 0.48 - ETA: 0s - loss: 0.6943 - accuracy: 0.48 - ETA: 0s - loss: 0.6941 - accuracy: 0.48 - ETA: 0s - loss: 0.6940 - accuracy: 0.48 - ETA: 0s - loss: 0.6940 - accuracy: 0.49 - 3s 1ms/sample - loss: 0.6939 - accuracy: 0.4956 - val_loss: 0.6932 - val_accuracy: 0.4916\n",
      "Epoch 9/10\n",
      "2137/2137 [==============================] - ETA: 3s - loss: 0.6928 - accuracy: 0.59 - ETA: 2s - loss: 0.6914 - accuracy: 0.55 - ETA: 1s - loss: 0.6916 - accuracy: 0.52 - ETA: 1s - loss: 0.6910 - accuracy: 0.54 - ETA: 1s - loss: 0.6926 - accuracy: 0.51 - ETA: 1s - loss: 0.6937 - accuracy: 0.50 - ETA: 1s - loss: 0.6926 - accuracy: 0.52 - ETA: 1s - loss: 0.6929 - accuracy: 0.51 - ETA: 1s - loss: 0.6929 - accuracy: 0.52 - ETA: 1s - loss: 0.6928 - accuracy: 0.52 - ETA: 1s - loss: 0.6929 - accuracy: 0.52 - ETA: 1s - loss: 0.6930 - accuracy: 0.52 - ETA: 1s - loss: 0.6923 - accuracy: 0.52 - ETA: 1s - loss: 0.6921 - accuracy: 0.52 - ETA: 1s - loss: 0.6925 - accuracy: 0.51 - ETA: 1s - loss: 0.6927 - accuracy: 0.51 - ETA: 1s - loss: 0.6927 - accuracy: 0.51 - ETA: 0s - loss: 0.6927 - accuracy: 0.51 - ETA: 0s - loss: 0.6935 - accuracy: 0.51 - ETA: 0s - loss: 0.6933 - accuracy: 0.51 - ETA: 0s - loss: 0.6930 - accuracy: 0.51 - ETA: 0s - loss: 0.6932 - accuracy: 0.51 - ETA: 0s - loss: 0.6933 - accuracy: 0.51 - ETA: 0s - loss: 0.6934 - accuracy: 0.51 - ETA: 0s - loss: 0.6929 - accuracy: 0.52 - ETA: 0s - loss: 0.6929 - accuracy: 0.52 - ETA: 0s - loss: 0.6929 - accuracy: 0.52 - ETA: 0s - loss: 0.6930 - accuracy: 0.51 - ETA: 0s - loss: 0.6931 - accuracy: 0.51 - ETA: 0s - loss: 0.6930 - accuracy: 0.51 - ETA: 0s - loss: 0.6931 - accuracy: 0.51 - ETA: 0s - loss: 0.6929 - accuracy: 0.51 - ETA: 0s - loss: 0.6929 - accuracy: 0.51 - ETA: 0s - loss: 0.6928 - accuracy: 0.51 - ETA: 0s - loss: 0.6927 - accuracy: 0.51 - 2s 1ms/sample - loss: 0.6927 - accuracy: 0.5129 - val_loss: 0.6932 - val_accuracy: 0.4916\n",
      "Epoch 10/10\n",
      "2137/2137 [==============================] - ETA: 2s - loss: 0.6885 - accuracy: 0.50 - ETA: 2s - loss: 0.6935 - accuracy: 0.50 - ETA: 2s - loss: 0.6951 - accuracy: 0.49 - ETA: 3s - loss: 0.6942 - accuracy: 0.50 - ETA: 3s - loss: 0.6938 - accuracy: 0.50 - ETA: 3s - loss: 0.6938 - accuracy: 0.50 - ETA: 3s - loss: 0.6938 - accuracy: 0.50 - ETA: 3s - loss: 0.6937 - accuracy: 0.50 - ETA: 3s - loss: 0.6942 - accuracy: 0.50 - ETA: 3s - loss: 0.6938 - accuracy: 0.50 - ETA: 2s - loss: 0.6932 - accuracy: 0.50 - ETA: 2s - loss: 0.6945 - accuracy: 0.48 - ETA: 2s - loss: 0.6952 - accuracy: 0.47 - ETA: 2s - loss: 0.6952 - accuracy: 0.48 - ETA: 2s - loss: 0.6951 - accuracy: 0.47 - ETA: 1s - loss: 0.6957 - accuracy: 0.48 - ETA: 1s - loss: 0.6956 - accuracy: 0.48 - ETA: 1s - loss: 0.6955 - accuracy: 0.48 - ETA: 1s - loss: 0.6954 - accuracy: 0.48 - ETA: 1s - loss: 0.6955 - accuracy: 0.49 - ETA: 1s - loss: 0.6954 - accuracy: 0.49 - ETA: 1s - loss: 0.6953 - accuracy: 0.49 - ETA: 1s - loss: 0.6953 - accuracy: 0.49 - ETA: 1s - loss: 0.6949 - accuracy: 0.49 - ETA: 0s - loss: 0.6949 - accuracy: 0.49 - ETA: 0s - loss: 0.6947 - accuracy: 0.49 - ETA: 0s - loss: 0.6946 - accuracy: 0.49 - ETA: 0s - loss: 0.6947 - accuracy: 0.49 - ETA: 0s - loss: 0.6946 - accuracy: 0.49 - ETA: 0s - loss: 0.6944 - accuracy: 0.49 - ETA: 0s - loss: 0.6944 - accuracy: 0.49 - ETA: 0s - loss: 0.6944 - accuracy: 0.49 - ETA: 0s - loss: 0.6944 - accuracy: 0.49 - ETA: 0s - loss: 0.6943 - accuracy: 0.49 - ETA: 0s - loss: 0.6943 - accuracy: 0.49 - ETA: 0s - loss: 0.6943 - accuracy: 0.49 - 2s 1ms/sample - loss: 0.6943 - accuracy: 0.4909 - val_loss: 0.6932 - val_accuracy: 0.4916\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Hidden_layer_10_units: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-Hidden_layer_1_units: 158</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Hidden_layer_2_units: 190</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-Hidden_layer_3_units: 46</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Hidden_layer_4_units: 158</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-Hidden_layer_5_units: 158</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Hidden_layer_6_units: 190</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-Hidden_layer_7_units: 142</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Hidden_layer_8_units: 46</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-Hidden_layer_9_units: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_units: 126</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-no. Of Hidden Layers: 10</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.5028037428855896</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x=X_train,\n",
    "             y=y_train,\n",
    "             epochs = EPOCHS,\n",
    "#             batch_size = 64,\n",
    "             callbacks=[early_stop],\n",
    "             validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Results in 1579318689/untitled_project</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Objective: Objective(name='val_accuracy', direction='max') Score: 0.5738317966461182</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Objective: Objective(name='val_accuracy', direction='max') Score: 0.5028037428855896</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'input_units': 78, 'no. Of Hidden Layers': 8, 'Hidden_layer_1_units': 222, 'Hidden_layer_2_units': 30, 'Hidden_layer_3_units': 30, 'Hidden_layer_4_units': 30, 'Hidden_layer_5_units': 30, 'Hidden_layer_6_units': 30, 'Hidden_layer_7_units': 30, 'Hidden_layer_8_units': 30}\n"
     ]
    }
   ],
   "source": [
    "print(tuner.results_summary()) # top 10 trials\n",
    "print(tuner.get_best_hyperparameters()[0].values) #values of best hyper-parameters\n",
    "#print(tuner.get_best_models()[0].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
