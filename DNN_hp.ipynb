{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN with Hyper-Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1336\n",
      "0    1336\n",
      "Name: Winner, dtype: int64\n",
      "X_train shape: (2137, 42) | X_test shape: (535, 42) | y_train shape: (2137,) | y_test shape: (535,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # disable GPU\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "\n",
    "#hyper-parameter tuning imports\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import time\n",
    "LOG_DIR = f\"{int(time.time())}\" # folder names as a timestamp\n",
    "\n",
    "SEED = 111 # constant seed for reproducibility\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "df = pd.read_csv(\"UFC_TRAIN.csv\")\n",
    "\n",
    "# tackling imbalance issue\n",
    "theMin = df[\"Winner\"].value_counts().min()\n",
    "minority = df[df[\"Winner\"]==1].iloc[0:theMin]\n",
    "undersampleMaj = df[df[\"Winner\"]==0].iloc[0:theMin]\n",
    "df = pd.concat([minority, undersampleMaj], axis=0)\n",
    "print(df[\"Winner\"].value_counts())\n",
    "\n",
    "# train/test split\n",
    "X = df.drop([\"date\",\"Winner\",\"B_fighter\",\"R_fighter\"], axis=1).values\n",
    "y = df[\"Winner\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape} | X_test shape: {X_test.shape} | y_train shape: {y_train.shape} | y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Parameters\n",
    "MIN = 30\n",
    "MAX = 256\n",
    "STEP = 16\n",
    "MAX_TRIALS = 2\n",
    "EXE_PER_TRIAL = 1\n",
    "EPOCHS = 10\n",
    "PATIENCE = 16\n",
    "\n",
    "# function to build the model (argument: hyper-parameter)\n",
    "def build_model(hp):\n",
    "    # model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # first layer's no. of neurons = hp.Int range of values to test\n",
    "    model.add(Dense(hp.Int(\"input_units\", min_value=MIN, max_value=MAX, step=STEP), activation='relu'))\n",
    "    \n",
    "    # range of 1 to 10 layers to test\n",
    "    for i in range(hp.Int(\"no. Of Hidden Layers\", 1, 5)):\n",
    "        # for each added layer, again test range of neurons and add dropout\n",
    "        model.add(Dense(hp.Int(f\"Hidden_layer_{i+1}_units\", min_value=MIN, max_value=MAX, step=STEP), activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "        build_model, # name of the function that builds the model\n",
    "        objective=\"val_accuracy\", # the thing that we're interested to trace\n",
    "        max_trials = MAX_TRIALS, # no. of combinations to try\n",
    "        executions_per_trial = EXE_PER_TRIAL, # no. of times to train each combination (true avg)\n",
    "        directory=LOG_DIR) # directory to save the outputs\n",
    "\n",
    "# prevent divergence of loss & val_loss via early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2137 samples, validate on 535 samples\n",
      "Epoch 1/10\n",
      "2137/2137 [==============================] - ETA: 2:23 - loss: 0.6937 - accuracy: 0.56 - ETA: 22s - loss: 0.7000 - accuracy: 0.5052 - ETA: 17s - loss: 0.7071 - accuracy: 0.484 - ETA: 13s - loss: 0.7027 - accuracy: 0.490 - ETA: 10s - loss: 0.7063 - accuracy: 0.483 - ETA: 7s - loss: 0.7037 - accuracy: 0.486 - ETA: 5s - loss: 0.7001 - accuracy: 0.51 - ETA: 4s - loss: 0.6980 - accuracy: 0.50 - ETA: 3s - loss: 0.6977 - accuracy: 0.49 - ETA: 2s - loss: 0.6967 - accuracy: 0.49 - ETA: 2s - loss: 0.6966 - accuracy: 0.50 - ETA: 2s - loss: 0.6978 - accuracy: 0.49 - ETA: 2s - loss: 0.6983 - accuracy: 0.48 - ETA: 1s - loss: 0.6977 - accuracy: 0.49 - ETA: 1s - loss: 0.6968 - accuracy: 0.49 - ETA: 1s - loss: 0.6958 - accuracy: 0.50 - ETA: 1s - loss: 0.6954 - accuracy: 0.50 - ETA: 0s - loss: 0.6959 - accuracy: 0.50 - ETA: 0s - loss: 0.6955 - accuracy: 0.50 - ETA: 0s - loss: 0.6951 - accuracy: 0.50 - ETA: 0s - loss: 0.6956 - accuracy: 0.50 - 4s 2ms/sample - loss: 0.6953 - accuracy: 0.5016 - val_loss: 0.6923 - val_accuracy: 0.5140\n",
      "Epoch 2/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.7015 - accuracy: 0.40 - ETA: 0s - loss: 0.6948 - accuracy: 0.49 - ETA: 0s - loss: 0.7009 - accuracy: 0.48 - ETA: 0s - loss: 0.6987 - accuracy: 0.48 - ETA: 0s - loss: 0.7000 - accuracy: 0.46 - ETA: 0s - loss: 0.6988 - accuracy: 0.47 - ETA: 0s - loss: 0.6979 - accuracy: 0.47 - ETA: 0s - loss: 0.6983 - accuracy: 0.47 - ETA: 0s - loss: 0.6981 - accuracy: 0.47 - ETA: 0s - loss: 0.6978 - accuracy: 0.48 - ETA: 0s - loss: 0.6981 - accuracy: 0.48 - ETA: 0s - loss: 0.6972 - accuracy: 0.49 - 1s 358us/sample - loss: 0.6974 - accuracy: 0.4918 - val_loss: 0.6931 - val_accuracy: 0.5084\n",
      "Epoch 3/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6854 - accuracy: 0.62 - ETA: 0s - loss: 0.6928 - accuracy: 0.54 - ETA: 0s - loss: 0.6952 - accuracy: 0.51 - ETA: 0s - loss: 0.6958 - accuracy: 0.51 - ETA: 0s - loss: 0.6951 - accuracy: 0.51 - ETA: 0s - loss: 0.6948 - accuracy: 0.50 - ETA: 0s - loss: 0.6939 - accuracy: 0.51 - ETA: 0s - loss: 0.6926 - accuracy: 0.52 - ETA: 0s - loss: 0.6934 - accuracy: 0.51 - ETA: 0s - loss: 0.6939 - accuracy: 0.51 - ETA: 0s - loss: 0.6947 - accuracy: 0.50 - ETA: 0s - loss: 0.6946 - accuracy: 0.50 - 1s 381us/sample - loss: 0.6944 - accuracy: 0.5115 - val_loss: 0.6932 - val_accuracy: 0.5028\n",
      "Epoch 4/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6762 - accuracy: 0.68 - ETA: 0s - loss: 0.6899 - accuracy: 0.58 - ETA: 0s - loss: 0.6918 - accuracy: 0.56 - ETA: 0s - loss: 0.6929 - accuracy: 0.54 - ETA: 0s - loss: 0.6922 - accuracy: 0.54 - ETA: 0s - loss: 0.6935 - accuracy: 0.53 - ETA: 0s - loss: 0.6944 - accuracy: 0.52 - ETA: 0s - loss: 0.6936 - accuracy: 0.52 - ETA: 0s - loss: 0.6929 - accuracy: 0.52 - ETA: 0s - loss: 0.6932 - accuracy: 0.52 - ETA: 0s - loss: 0.6931 - accuracy: 0.52 - ETA: 0s - loss: 0.6937 - accuracy: 0.51 - 1s 360us/sample - loss: 0.6937 - accuracy: 0.5147 - val_loss: 0.6931 - val_accuracy: 0.5121\n",
      "Epoch 5/10\n",
      "2137/2137 [==============================] - ETA: 0s - loss: 0.7057 - accuracy: 0.34 - ETA: 0s - loss: 0.6919 - accuracy: 0.48 - ETA: 0s - loss: 0.6934 - accuracy: 0.49 - ETA: 0s - loss: 0.6917 - accuracy: 0.51 - ETA: 0s - loss: 0.6924 - accuracy: 0.51 - ETA: 0s - loss: 0.6930 - accuracy: 0.51 - ETA: 0s - loss: 0.6924 - accuracy: 0.50 - ETA: 0s - loss: 0.6919 - accuracy: 0.50 - ETA: 0s - loss: 0.6922 - accuracy: 0.50 - ETA: 0s - loss: 0.6925 - accuracy: 0.50 - ETA: 0s - loss: 0.6929 - accuracy: 0.50 - 1s 358us/sample - loss: 0.6929 - accuracy: 0.5035 - val_loss: 0.6927 - val_accuracy: 0.5252\n",
      "Epoch 6/10\n",
      "2137/2137 [==============================] - ETA: 0s - loss: 0.7024 - accuracy: 0.40 - ETA: 0s - loss: 0.6957 - accuracy: 0.47 - ETA: 0s - loss: 0.6934 - accuracy: 0.50 - ETA: 0s - loss: 0.6932 - accuracy: 0.50 - ETA: 0s - loss: 0.6926 - accuracy: 0.51 - ETA: 0s - loss: 0.6912 - accuracy: 0.52 - ETA: 0s - loss: 0.6925 - accuracy: 0.51 - ETA: 0s - loss: 0.6926 - accuracy: 0.51 - ETA: 0s - loss: 0.6931 - accuracy: 0.50 - ETA: 0s - loss: 0.6928 - accuracy: 0.50 - ETA: 0s - loss: 0.6934 - accuracy: 0.49 - ETA: 0s - loss: 0.6938 - accuracy: 0.49 - ETA: 0s - loss: 0.6936 - accuracy: 0.49 - ETA: 0s - loss: 0.6931 - accuracy: 0.50 - 1s 470us/sample - loss: 0.6933 - accuracy: 0.5021 - val_loss: 0.6917 - val_accuracy: 0.5308\n",
      "Epoch 7/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.7019 - accuracy: 0.34 - ETA: 0s - loss: 0.6958 - accuracy: 0.47 - ETA: 0s - loss: 0.6963 - accuracy: 0.47 - ETA: 0s - loss: 0.6949 - accuracy: 0.50 - ETA: 0s - loss: 0.6928 - accuracy: 0.50 - ETA: 0s - loss: 0.6938 - accuracy: 0.50 - ETA: 0s - loss: 0.6924 - accuracy: 0.52 - ETA: 0s - loss: 0.6922 - accuracy: 0.52 - ETA: 0s - loss: 0.6926 - accuracy: 0.51 - ETA: 0s - loss: 0.6922 - accuracy: 0.51 - ETA: 0s - loss: 0.6926 - accuracy: 0.51 - ETA: 0s - loss: 0.6929 - accuracy: 0.51 - ETA: 0s - loss: 0.6934 - accuracy: 0.51 - ETA: 0s - loss: 0.6936 - accuracy: 0.51 - 1s 462us/sample - loss: 0.6935 - accuracy: 0.5110 - val_loss: 0.6916 - val_accuracy: 0.5514\n",
      "Epoch 8/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6903 - accuracy: 0.43 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 1s - loss: 0.6932 - accuracy: 0.54 - ETA: 1s - loss: 0.6927 - accuracy: 0.54 - ETA: 1s - loss: 0.6940 - accuracy: 0.54 - ETA: 1s - loss: 0.6925 - accuracy: 0.53 - ETA: 1s - loss: 0.6927 - accuracy: 0.52 - ETA: 0s - loss: 0.6928 - accuracy: 0.52 - ETA: 0s - loss: 0.6932 - accuracy: 0.51 - ETA: 0s - loss: 0.6929 - accuracy: 0.52 - ETA: 0s - loss: 0.6924 - accuracy: 0.52 - ETA: 0s - loss: 0.6922 - accuracy: 0.53 - ETA: 0s - loss: 0.6924 - accuracy: 0.53 - ETA: 0s - loss: 0.6926 - accuracy: 0.53 - ETA: 0s - loss: 0.6914 - accuracy: 0.54 - ETA: 0s - loss: 0.6918 - accuracy: 0.54 - ETA: 0s - loss: 0.6918 - accuracy: 0.54 - 1s 511us/sample - loss: 0.6920 - accuracy: 0.5414 - val_loss: 0.6898 - val_accuracy: 0.5738\n",
      "Epoch 9/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6987 - accuracy: 0.43 - ETA: 0s - loss: 0.6909 - accuracy: 0.52 - ETA: 0s - loss: 0.6918 - accuracy: 0.55 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - ETA: 0s - loss: 0.6896 - accuracy: 0.56 - ETA: 0s - loss: 0.6922 - accuracy: 0.54 - ETA: 0s - loss: 0.6923 - accuracy: 0.54 - ETA: 0s - loss: 0.6930 - accuracy: 0.53 - ETA: 0s - loss: 0.6924 - accuracy: 0.53 - ETA: 0s - loss: 0.6920 - accuracy: 0.53 - ETA: 0s - loss: 0.6925 - accuracy: 0.52 - ETA: 0s - loss: 0.6919 - accuracy: 0.53 - ETA: 0s - loss: 0.6924 - accuracy: 0.52 - ETA: 0s - loss: 0.6923 - accuracy: 0.52 - 1s 447us/sample - loss: 0.6925 - accuracy: 0.5246 - val_loss: 0.6911 - val_accuracy: 0.5533\n",
      "Epoch 10/10\n",
      "2137/2137 [==============================] - ETA: 0s - loss: 0.6796 - accuracy: 0.53 - ETA: 1s - loss: 0.6844 - accuracy: 0.53 - ETA: 1s - loss: 0.6879 - accuracy: 0.54 - ETA: 1s - loss: 0.6854 - accuracy: 0.55 - ETA: 1s - loss: 0.6873 - accuracy: 0.56 - ETA: 1s - loss: 0.6905 - accuracy: 0.54 - ETA: 1s - loss: 0.6900 - accuracy: 0.54 - ETA: 0s - loss: 0.6895 - accuracy: 0.53 - ETA: 0s - loss: 0.6884 - accuracy: 0.53 - ETA: 0s - loss: 0.6893 - accuracy: 0.54 - ETA: 0s - loss: 0.6891 - accuracy: 0.53 - ETA: 0s - loss: 0.6901 - accuracy: 0.54 - ETA: 0s - loss: 0.6895 - accuracy: 0.54 - ETA: 0s - loss: 0.6904 - accuracy: 0.53 - ETA: 0s - loss: 0.6904 - accuracy: 0.53 - ETA: 0s - loss: 0.6902 - accuracy: 0.53 - ETA: 0s - loss: 0.6901 - accuracy: 0.53 - 1s 535us/sample - loss: 0.6897 - accuracy: 0.5367 - val_loss: 0.6882 - val_accuracy: 0.5776\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Hidden_layer_1_units: 142</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-Hidden_layer_2_units: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Hidden_layer_3_units: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-Hidden_layer_4_units: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_units: 222</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-no. Of Hidden Layers: 4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.5775700807571411</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2137 samples, validate on 535 samples\n",
      "Epoch 1/10\n",
      "2137/2137 [==============================] - ETA: 1:43 - loss: 0.6915 - accuracy: 0.65 - ETA: 20s - loss: 0.6862 - accuracy: 0.6062 - ETA: 6s - loss: 0.6943 - accuracy: 0.535 - ETA: 3s - loss: 0.6938 - accuracy: 0.52 - ETA: 2s - loss: 0.6951 - accuracy: 0.52 - ETA: 1s - loss: 0.6961 - accuracy: 0.52 - ETA: 0s - loss: 0.6956 - accuracy: 0.51 - ETA: 0s - loss: 0.6944 - accuracy: 0.51 - 2s 1ms/sample - loss: 0.6941 - accuracy: 0.5194 - val_loss: 0.6859 - val_accuracy: 0.5832\n",
      "Epoch 2/10\n",
      "2137/2137 [==============================] - ETA: 0s - loss: 0.7032 - accuracy: 0.46 - ETA: 0s - loss: 0.6914 - accuracy: 0.54 - ETA: 0s - loss: 0.6963 - accuracy: 0.50 - ETA: 0s - loss: 0.6954 - accuracy: 0.50 - ETA: 0s - loss: 0.6934 - accuracy: 0.52 - ETA: 0s - loss: 0.6919 - accuracy: 0.53 - ETA: 0s - loss: 0.6899 - accuracy: 0.53 - ETA: 0s - loss: 0.6906 - accuracy: 0.53 - 1s 265us/sample - loss: 0.6900 - accuracy: 0.5386 - val_loss: 0.6810 - val_accuracy: 0.5776\n",
      "Epoch 3/10\n",
      "2137/2137 [==============================] - ETA: 0s - loss: 0.6670 - accuracy: 0.62 - ETA: 0s - loss: 0.6836 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.54 - ETA: 0s - loss: 0.6909 - accuracy: 0.54 - ETA: 0s - loss: 0.6879 - accuracy: 0.55 - ETA: 0s - loss: 0.6895 - accuracy: 0.55 - ETA: 0s - loss: 0.6867 - accuracy: 0.56 - ETA: 0s - loss: 0.6861 - accuracy: 0.56 - 1s 265us/sample - loss: 0.6850 - accuracy: 0.5695 - val_loss: 0.6732 - val_accuracy: 0.5757\n",
      "Epoch 4/10\n",
      "2137/2137 [==============================] - ETA: 0s - loss: 0.6682 - accuracy: 0.43 - ETA: 0s - loss: 0.6771 - accuracy: 0.56 - ETA: 0s - loss: 0.6727 - accuracy: 0.58 - ETA: 0s - loss: 0.6709 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.58 - ETA: 0s - loss: 0.6775 - accuracy: 0.57 - ETA: 0s - loss: 0.6769 - accuracy: 0.56 - ETA: 0s - loss: 0.6746 - accuracy: 0.58 - 1s 265us/sample - loss: 0.6755 - accuracy: 0.5807 - val_loss: 0.6617 - val_accuracy: 0.5907\n",
      "Epoch 5/10\n",
      "2137/2137 [==============================] - ETA: 0s - loss: 0.6979 - accuracy: 0.53 - ETA: 0s - loss: 0.6479 - accuracy: 0.64 - ETA: 0s - loss: 0.6545 - accuracy: 0.62 - ETA: 0s - loss: 0.6578 - accuracy: 0.62 - ETA: 0s - loss: 0.6621 - accuracy: 0.61 - ETA: 0s - loss: 0.6624 - accuracy: 0.60 - ETA: 0s - loss: 0.6654 - accuracy: 0.59 - ETA: 0s - loss: 0.6683 - accuracy: 0.58 - ETA: 0s - loss: 0.6705 - accuracy: 0.58 - 1s 287us/sample - loss: 0.6708 - accuracy: 0.5826 - val_loss: 0.6571 - val_accuracy: 0.6000\n",
      "Epoch 6/10\n",
      "2137/2137 [==============================] - ETA: 0s - loss: 0.7146 - accuracy: 0.59 - ETA: 0s - loss: 0.6716 - accuracy: 0.60 - ETA: 0s - loss: 0.6641 - accuracy: 0.61 - ETA: 0s - loss: 0.6675 - accuracy: 0.59 - ETA: 0s - loss: 0.6664 - accuracy: 0.59 - ETA: 0s - loss: 0.6655 - accuracy: 0.59 - ETA: 0s - loss: 0.6631 - accuracy: 0.59 - ETA: 0s - loss: 0.6634 - accuracy: 0.60 - 1s 272us/sample - loss: 0.6637 - accuracy: 0.5994 - val_loss: 0.6577 - val_accuracy: 0.6093\n",
      "Epoch 7/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6486 - accuracy: 0.59 - ETA: 0s - loss: 0.6795 - accuracy: 0.55 - ETA: 0s - loss: 0.6671 - accuracy: 0.59 - ETA: 0s - loss: 0.6647 - accuracy: 0.59 - ETA: 0s - loss: 0.6634 - accuracy: 0.59 - ETA: 0s - loss: 0.6622 - accuracy: 0.59 - ETA: 0s - loss: 0.6590 - accuracy: 0.59 - ETA: 0s - loss: 0.6575 - accuracy: 0.60 - ETA: 0s - loss: 0.6595 - accuracy: 0.59 - 1s 281us/sample - loss: 0.6610 - accuracy: 0.5957 - val_loss: 0.6535 - val_accuracy: 0.6019\n",
      "Epoch 8/10\n",
      "2137/2137 [==============================] - ETA: 0s - loss: 0.6330 - accuracy: 0.71 - ETA: 0s - loss: 0.6523 - accuracy: 0.60 - ETA: 0s - loss: 0.6566 - accuracy: 0.59 - ETA: 0s - loss: 0.6561 - accuracy: 0.60 - ETA: 0s - loss: 0.6542 - accuracy: 0.60 - ETA: 0s - loss: 0.6536 - accuracy: 0.60 - ETA: 0s - loss: 0.6534 - accuracy: 0.60 - ETA: 0s - loss: 0.6546 - accuracy: 0.60 - 1s 248us/sample - loss: 0.6536 - accuracy: 0.6083 - val_loss: 0.6475 - val_accuracy: 0.6075\n",
      "Epoch 9/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6449 - accuracy: 0.62 - ETA: 0s - loss: 0.6419 - accuracy: 0.62 - ETA: 0s - loss: 0.6413 - accuracy: 0.61 - ETA: 0s - loss: 0.6430 - accuracy: 0.61 - ETA: 0s - loss: 0.6447 - accuracy: 0.61 - ETA: 0s - loss: 0.6467 - accuracy: 0.61 - ETA: 0s - loss: 0.6500 - accuracy: 0.60 - ETA: 0s - loss: 0.6490 - accuracy: 0.60 - 1s 287us/sample - loss: 0.6497 - accuracy: 0.6046 - val_loss: 0.6460 - val_accuracy: 0.6131\n",
      "Epoch 10/10\n",
      "2137/2137 [==============================] - ETA: 1s - loss: 0.6564 - accuracy: 0.53 - ETA: 0s - loss: 0.6581 - accuracy: 0.57 - ETA: 0s - loss: 0.6506 - accuracy: 0.59 - ETA: 0s - loss: 0.6477 - accuracy: 0.60 - ETA: 0s - loss: 0.6430 - accuracy: 0.61 - ETA: 0s - loss: 0.6476 - accuracy: 0.61 - ETA: 0s - loss: 0.6479 - accuracy: 0.61 - ETA: 0s - loss: 0.6490 - accuracy: 0.60 - 1s 285us/sample - loss: 0.6528 - accuracy: 0.6022 - val_loss: 0.6442 - val_accuracy: 0.6243\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Hidden_layer_1_units: 190</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-Hidden_layer_2_units: 222</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Hidden_layer_3_units: 62</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-Hidden_layer_4_units: 222</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_units: 30</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-no. Of Hidden Layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6242990493774414</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x=X_train,\n",
    "             y=y_train,\n",
    "             epochs = EPOCHS,\n",
    "#             batch_size = 64,\n",
    "             callbacks=[early_stop],\n",
    "             validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Results in 1579467462/untitled_project</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Objective: Objective(name='val_accuracy', direction='max') Score: 0.6242990493774414</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Objective: Objective(name='val_accuracy', direction='max') Score: 0.5775700807571411</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'input_units': 30, 'no. Of Hidden Layers': 1, 'Hidden_layer_1_units': 190, 'Hidden_layer_2_units': 222, 'Hidden_layer_3_units': 62, 'Hidden_layer_4_units': 222}\n"
     ]
    }
   ],
   "source": [
    "print(tuner.results_summary()) # top 10 trials\n",
    "print(tuner.get_best_hyperparameters()[0].values) #values of best hyper-parameters\n",
    "#print(tuner.get_best_models()[0].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
